# -*- coding: utf-8 -*-
"""VetPal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LuYnIw70qthnU8pEslmKyY2giAyQh59h

Vet-Pal: A veterinary consultant chatbot
Description: The planned chatbot is a veterinary consultant that can be asked questions about the treatment of present ailments of a pet. It can provide information about first aid, and any initial home remedies and commonly available on the shelf products. But the chatbot won't go beyond what it currently knows since an actual vet will be able to assess more serious cases

# Installation
"""

!pip install rasa

!pip install -U tables

!pip install spacy==3.5.2

!python -m spacy download en_core_web_sm

!pip install -U nest_asyncio

"""# Creating Initial Test Project"""

import os
import rasa
import nest_asyncio

nest_asyncio.apply()
print("Event loop ready.")

from rasa.cli.scaffold import create_initial_project

project = "test-project"
create_initial_project(project)

# move into project directory and show files
os.chdir(project)
print(os.listdir("."))

config = "config.yml"
training_files = "data/"
domain = "domain.yml"
output = "models/"
print(config, training_files, domain, output)

"""# Data Cleaning"""

import pandas as pd

# Load the Excel file
file_path = '/content/Pet_Dataset.xlsx'  # Update the path if necessary
xlsx = pd.ExcelFile(file_path)

# Print sheet names and load the first sheet by default
print("Sheet names:", xlsx.sheet_names)
sheet_name = xlsx.sheet_names[0]
df = pd.read_excel(file_path, sheet_name=sheet_name)

# Preview the initial data
print("Initial Data Preview:")
df.head()

# Basic Data Information
print("\nData Information:")
df.info()

# Handle Missing Values
print("\nHandling Missing Values...")
# Text columns: Replace missing values with a placeholder message
for column in df.select_dtypes(include=['object']).columns:
    df[column].fillna('No information available.', inplace=True)

# Remove Duplicates
print("\nRemoving Duplicates...")
df.drop_duplicates(inplace=True)

# Standardize Column Names
print("\nStandardizing Column Names...")
df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]

# Text Standardization: Strip extra whitespace and capitalize entries where necessary
print("\nStandardizing Text Data...")
for column in df.select_dtypes(include=['object']).columns:
    df[column] = df[column].str.strip().str.capitalize()

# Final Preview of the Cleaned Data
print("\nCleaned Data Preview:")
df.head()

# Save Cleaned Data
output_file = 'Cleaned_Pet_Dataset_VetPal.xlsx'
df.to_excel(output_file, index=False)
print(f"Cleaned data saved as '{output_file}'")

"""# Data Preperation"""

import os
import logging
import pandas as pd
import yaml

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Configuration Constants
CONFIG = {
    "input_file": "/content/test-project/Cleaned_Pet_Dataset_VetPal.xlsx",
    "output_csv": "/content/Cleaned_Pet_Dataset.csv",
    "nlu_file": "/content/test-project/data/nlu.yml",
    "domain_file": "/content/test-project/domain.yml",
    "stories_file": "/content/test-project/data/stories.yml",
    "required_columns": ['pet_diseases', 'symptoms', 'description', 'first_aid', 'products/medicine'],
    "entities": ['symptoms', 'diseases', 'description', 'first_aid', 'products', 'urgency']
}

# Utility Functions

def load_and_clean_data(input_file, required_columns):
    """Load and clean dataset."""
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"Input file '{input_file}' not found.")

    data = pd.read_excel(input_file)
    data.columns = [col.lower().replace(' ', '_') for col in data.columns]

    missing_columns = [col for col in required_columns if col not in data.columns]
    if missing_columns:
        raise ValueError(f"Missing columns: {missing_columns}")

    data.dropna(subset=required_columns, inplace=True)
    return data

def save_cleaned_csv(data, output_csv):
    """Save cleaned dataset to CSV."""
    data.to_csv(output_csv, index=False)
    logging.info(f"Cleaned dataset saved to {output_csv}")

# NLU File Generation

def generate_nlu(data, nlu_file):
    """Generate nlu.yml file."""
    with open(nlu_file, 'w') as file:
        file.write("version: \"3.1\"\n")
        file.write("nlu:\n")

        static_intents = {
            "fallback": ["I don't understand", "That doesn't make sense", "What are you talking about?", "Sorry, I didn't get that", "I am confused"],
            "bot_challenge": ["Are you a bot?", "What are you?", "Are you human or a bot?"],
            "goodbye": ["Goodbye", "See you later", "Bye"],
            "action_inquiry": ["What should I do)", "How can I treat this?", "How can I treat issue?", "What steps should I take to help my pet?", "Can you give me first-aid tips?", "What should I do", "What’s the best course of action?", "Is there any medication I can use?", "What’s the immediate first aid for this condition?", "Can you guide me on what to do next?"],
            "thanks": ["Thank you", "Thanks a lot"],
        }

        for intent, examples in static_intents.items():
            file.write(f"- intent: {intent}\n  examples: |\n")
            for ex in examples:
                file.write(f"    - {ex}\n")

        for index, row in data.iterrows():
            symptoms, disease = row['symptoms'], row['pet_diseases']
            if pd.notna(symptoms) and pd.notna(disease):
                intent_name = f"symptom_inquiry_{index}"
                examples = [
                    f"My pet has {symptoms}. What does it mean?",
                    f"Symptoms include {symptoms}. Can you help?",
                    f"My pet is showing signs of {symptoms}. Should I be concerned?",
                    f"I'm noticing {symptoms} in my pet. What could it indicate?",
                    f"What does it mean if my pet has {symptoms}?",
                    f"My pet has {symptoms}. Should I consult a vet?",
                    f"My pet has {symptoms}. What does it mean?",
                    f"How serious is it if my pet has {symptoms}"
                ]
                file.write(f"- intent: {intent_name}\n  examples: |\n")
                for ex in examples:
                    file.write(f"    - {ex}\n")
    logging.info(f"nlu.yml generated at {nlu_file}")

# Domain File Generation

def generate_domain(data, domain_file, entities):
    """Generate domain.yml."""
    utterances = set()  # Proper initialization to track generated keys
    with open(domain_file, 'w') as file:
        file.write("version: \"3.1\"\n")
        file.write("\nactions:\n  - action_fallback\n  - action_custom_fallback\n")
        file.write("\nintents:\n  - bot_challenge\n  - thanks\n  - fallback\n  - goodbye\n  - action_inquiry\n")


        for index in data.index:
            file.write(f"  - symptom_inquiry_{index}\n")

        file.write("\nslots:\n")
        for entity in entities:
            file.write(f"  {entity}:\n    type: text\n    influence_conversation: true\n    mappings:\n      - type: from_text\n")
        file.write("\nresponses:\n")
        file.write("  utter_bot_identity:\n    - text: \"I am VetPal a virtual assistant here to help you.\"\n")
        file.write("  utter_you_are_welcome:\n    - text: \"You are welcome!\"\n")
        file.write("  utter_goodbye:\n    - text: \"Goodbye! Have a great day!\"\n")

        # Dynamic responses for symptom and action inquiry
        for index, row in data.iterrows():
            disease = row.get("pet_diseases", "Unknown Disease").replace("\n", " ")
            symptoms = row.get("symptoms", "No symptoms provided.")
            description = row.get("description", "No description available.")
            first_aid = (
                row.get("first_aid", "No first aid available.").replace("\n", " ")
                if pd.notna(row.get("first_aid"))
                else "No first aid available."
            )
            products = (
                row.get("products/medicine", "No recommended products.").replace("\n", " ")
                if pd.notna(row.get("products/medicine"))
                else "No recommended products."
            )
            urgency = "If symptoms persist, consult a veterinarian immediately."

            # Symptom inquiry response
            symptom_response_key = f"utter_symptom_inquiry_{index}"
            if symptom_response_key not in utterances:
                file.write(f"  {symptom_response_key}:\n")
                file.write("    - text: ")
                file.write(f"Your pet might have {disease}. ")
                file.write(f"{description}\n")
                utterances.add(symptom_response_key)

            # Action inquiry response
            action_response_key = f"utter_action_inquiry_{index}"
            if action_response_key not in utterances:
                file.write(f"  {action_response_key}:\n")
                file.write("    - text: |")
                file.write(f"\n        First Aid Tips:\n")
                for line in first_aid.split(". "):  # Split into sentences for better formatting
                    file.write(f"          - {line.strip()}.\n")
                file.write(f"        Products to Try: {products.strip()}\n")
                file.write(f"        Next Steps: {urgency}\n")
                utterances.add(action_response_key)
    logging.info(f"domain.yml generated at {domain_file}")

# Stories File Generation

def generate_stories(data, stories_file):
    """Generate stories.yml."""
    stories = set()  # Track unique story combinations to avoid duplicates
    with open(stories_file, 'w') as file:
        file.write("version: \"3.1\"\n")
        file.write("stories:\n")
        file.write("- story: Fallback response\n")
        file.write("  steps:\n  - intent: fallback\n  - action: action_fallback\n")
        file.write("- story: User asks if bot\n")
        file.write("  steps:\n  - intent: bot_challenge\n  - action: utter_bot_identity\n  - intent: thanks\n  - action: utter_you_are_welcome\n")


        # Loop through the dataset
        for index, row in data.iterrows():
            disease = str(row.get("pet_diseases", "Unknown Disease")).replace("\n", " ")
            symptoms = str(row.get("symptoms", "No symptoms provided."))

            # Skip if either disease or symptoms are missing
            if disease == "Unknown Disease" or symptoms == "No symptoms provided.":
                print(f"Skipped story generation for row {index} due to missing data.")
                continue

            # Generate a unique story name
            story_key = f"story_symptom_inquiry_{index}"

            # Check if story already exists
            if story_key in stories:
                print(f"Duplicate story found: {story_key}. Skipping.")
                continue

            stories.add(story_key)  # Add to the set of generated stories

            # Generate story for symptom inquiry
            file.write(f"- story: Provide advice for {disease}\n")
            file.write("  steps:\n")
            file.write(f"  - intent: symptom_inquiry_{index}\n")
            file.write(f"  - action: utter_symptom_inquiry_{index}\n")


            # Generate follow-up story for action inquiry
            file.write(f"- story: Follow-up advice for {disease}\n")
            file.write("  steps:\n")
            file.write(f"  - action: utter_symptom_inquiry_{index}\n")
            file.write("  - intent: action_inquiry\n")
            file.write(f"  - action: utter_action_inquiry_{index}\n")
    logging.info(f"stories.yml generated at {stories_file}")

# Execution Pipeline
try:
    data = load_and_clean_data(CONFIG['input_file'], CONFIG['required_columns'])
    save_cleaned_csv(data, CONFIG['output_csv'])
    generate_nlu(data, CONFIG['nlu_file'])
    generate_domain(data, CONFIG['domain_file'], CONFIG['entities'])
    generate_stories(data, CONFIG['stories_file'])
except Exception as e:
    logging.error(f"An error occurred: {e}")

"""# Data Training Model

"""

!rasa data validate

model_path =  rasa.train(domain, config, [training_files], output)
print(model_path)

"""# Chatbot Interaction"""

import subprocess

# Start the Rasa Action Server
action_server_process = subprocess.Popen(["rasa", "run", "actions", "--port", "5055"])

import asyncio
from rasa.core.agent import Agent
from rasa.utils.endpoints import EndpointConfig

# Define paths
model_path = "models/20250105-161208-frosty-tub.tar.gz"  # Adjust if necessary
action_endpoint = EndpointConfig(url="http://localhost:5055/webhook")

# Load the Rasa agent
agent = Agent.load(model_path, action_endpoint=action_endpoint)

# Asynchronous chat function
async def chat(agent):
    print("Bot is ready to chat! Type 'quit' to exit.")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            print("Goodbye!")
            break
        # Handle user input asynchronously
        responses = await agent.handle_text(user_input)
        for response in responses:
            print(f"Bot: {response['text']}")

# Run the chat function
asyncio.run(chat(agent))

"""# Model Evaluation"""

!rasa test